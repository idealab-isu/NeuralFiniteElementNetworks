{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "328d5c09-c198-4586-97d0-5e485c4fc9df",
   "metadata": {},
   "source": [
    "# Finite Element Inspired Neural PDE Solvers\n",
    "\n",
    "\n",
    "Neural PDEs are a termed used to describe machine learning models which\n",
    "model Partial Differential Equations. Within Neural PDEs there are two\n",
    "different approaches; data-driven, and data-free. Data-driven approaches\n",
    "are similar to traditional machine learning tasks, using massive amounts\n",
    "of data to train highly parameterized regression models. Data-free\n",
    "approaches, such as Physics-Informed Neural Networks or Neural Finite\n",
    "Element Networks (NFENs), the work outlined in this post, do not require\n",
    "any ground truth data. These models are optimized to minimize an\n",
    "objective function formulated by the target Partial Differential\n",
    "Equation (PDE).\n",
    "\n",
    "Let’s use the Poisson Equation as an example.\n",
    "\n",
    "$$\\begin{align}\n",
    "    - \\mathbf{{\\nabla}}\\cdot [\\nu(\\mathbf{x}; q) \\mathbf{{\\nabla}}u(\\mathbf{x}; q)] &= f(\\mathbf{x}) \\ \\ \\text{in} \\ \\ \\Omega, \\\\\n",
    "    \\alpha u + {\\beta} (\\nabla u\\cdot \\hat{\\mathbf{x}{n}}) &= g(\\mathbf{x}) \\ \\ \\text{on}\\ \\ \\Gamma_o,\n",
    "\\end{align}$$\n",
    "\n",
    "Where $u(x)$ is a scalar function indicative of the mass density,\n",
    "electric potential, temperature, or surface indicator function,\n",
    "depending on your application of the Poisson Equation. $\\nu$ is the\n",
    "diffusivity coefficient, and functions $f(\\mathbf{x})$ and\n",
    "$g(\\mathbf{x})$ are forcing functions. Lastly, different boundary\n",
    "conditions (Dirichlet, Neumann, Robin) are produced by varying\n",
    "${\\alpha}$ and ${\\beta}$, e.g., $(\\alpha, \\beta) = (1,0)$ denotes\n",
    "Dirichlet boundary condition, whereas $(\\alpha, \\beta) = (0,1)$\n",
    "represents Neumann condition.\n",
    "\n",
    "## Data-Driven Approach\n",
    "\n",
    "In the data-driven approach to modeling the Poisson Equation one would\n",
    "need a dataset of field solutions for the Poisson Equation. Variability\n",
    "in the dataset could be from a range of diffusivity values, different\n",
    "boundaries conditions, etc. The machine learning model would be trained\n",
    "to regress the final field solution given certain input values such as\n",
    "diffusivity values or boundary conditions. The loss function in this\n",
    "scenario is most likely a simple reconstruction loss using the\n",
    "mean-squared-error between the predicted field solution and the ground\n",
    "truth field solution from the dataset.\n",
    "\n",
    "## Data-Free Approach\n",
    "\n",
    "In the data-free approach to modeling the Poisson Equation there is no\n",
    "need for a dataset of ground truth values since we are constructing our\n",
    "loss function from the Poisson Equation itself. Constructing the\n",
    "data-free loss function for the Poisson Equation is very straight\n",
    "forward. Our neural network will make predictions of the field solution,\n",
    "so it will be a parameterized approximation of $u(\\mathbf{x})$.\n",
    "Concretely, we replace $u(\\mathbf{x})$ in the Poisson Equation with\n",
    "$u_{\\theta}(\\mathbf{x})$ where $u_{\\theta}(\\mathbf{x})$ is the predicted\n",
    "field solution from the neural network parameterized by $\\theta$. Since\n",
    "we have replaced $u(\\mathbf{x})$ with $u_{\\theta}(\\mathbf{x})$, to\n",
    "satisfy the Poisson Equation and structure our loss function we need to\n",
    "find the spatial derivatives of $u_{\\theta}(\\mathbf{x})$. Once we are\n",
    "able to compute the Laplacian of our predicted field solution\n",
    "$u_{\\theta}(\\mathbf{x})$, we can optimize the parameters of the neural\n",
    "network such that its output field solution satisfies the given forcing\n",
    "function $f(\\mathbf{x})$.\n",
    "\n",
    "So, by substituting our neural network, $u_{\\theta}(\\mathbf{x})$, into\n",
    "the Poisson equation for our scalar function $u(x)$ we get the\n",
    "following.\n",
    "\n",
    "$$\\begin{align}\n",
    "    - \\mathbf{{\\nabla}}\\cdot [\\nu(\\mathbf{x}; q) \\mathbf{{\\nabla}}u_{\\theta}(\\mathbf{x}; q)] &= f(\\mathbf{x}) \\ \\ \\text{in} \\ \\ \\Omega, \\\\\n",
    "    \\alpha u_{\\theta} + {\\beta} (\\nabla u_{\\theta}\\cdot \\hat{\\mathbf{x}{n}}) &= g(x) \\ \\ \\text{on}\\ \\ \\Gamma_o,\n",
    "    \\end{align}$$\n",
    "\n",
    "The loss function for a data-free neural PDE Solver is given as follows.\n",
    "\n",
    "$$\\mathcal{L} = \\int_{\\Omega} \\nu(\\mathbf{x}; q)|\\mathbf{{\\nabla}}u_{\\theta}(\\mathbf{x}; q)|^2 d\\mathbf{x}$$\n",
    "\n",
    "Both methods have their trade-offs. The Data-Driven approaches have\n",
    "demonstrated better performance than their Data-Free counterparts at the\n",
    "expense of its data requirements. Data-Free methods are more aligned\n",
    "with the underlying PDE, but can be challenging to train and are often\n",
    "incapable of generalizing to unseen circumstances of the PDE it was\n",
    "optimized for.\n",
    "\n",
    "## Neural Finite Element Networks\n",
    "\n",
    "The focus of this post is Neural Finite Element Networks, which fall\n",
    "under the data-free regime. In data-free methods the loss function is\n",
    "formulated directly from the target PDE, requiring the computation of\n",
    "spatial gradients to formulate the target PDE. Computing these spatial\n",
    "gradients is not trivial, and is the major contribution of Neural Finite\n",
    "Element Networks. Previous methods leveraged the Automatic\n",
    "Differentiation framework used to optimize the parameters of the neural\n",
    "network to compute the spatial gradients. In Neural Finite Element\n",
    "Networks these spatial derivatives are computed via Finite Element\n",
    "Method (FEM). Computing spatial derivatives with FEM allows NFENs to\n",
    "directly predict a discretization of the entire field solution. If the\n",
    "discretization of the domain is a uniform grid, like an image, these\n",
    "methods are able to use any image-based neural network architecture,\n",
    "e.g., convolutional neural networks and vision transformers. In the\n",
    "following section we present NFENs through two different problem\n",
    "formulations our works have addressed, specifically, solving the Poisson\n",
    "equation over a distribution of material diffusivity coefficient fields,\n",
    "and solving the Poisson equation over a distribution of irregular\n",
    "geometries inside of the domain. We have also included a brief overview\n",
    "of FEM in an appendix section at the end of this post.\n",
    "\n",
    "```{figure} Figures/ibn_framework_u_theta.png\n",
    "---\n",
    "name: fig-ibn-framework\n",
    "---\n",
    "Outline of an NFEN framework which maps an irregular geometry to the field solution of the given PDE, in this example the Poisson equation, to its field solution over the irregular geometry.\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Neural Finite Element Networks\n",
    "\n",
    "NFEN is a machine learning framework that learns a mapping between some\n",
    "input, a coefficient field, an object boundary, etc. to the field\n",
    "solution of the target PDE. {numref}`fig-ibn-framework` provides an overview of the\n",
    "NFEN framework predicting field solutions to the Poisson equation over\n",
    "an object boundary. The loss term for NFENs is the residual of the\n",
    "target PDE, where each term in the PDE is computed via FEMs. Since the\n",
    "entire loss term is computed from the output of the NFEN this type of\n",
    "model falls under the data-free regime of Neural PDE Solvers, and as our\n",
    "results will show, even Neural PDE *Operators*, capable of solving the\n",
    "target PDE over variable inputs not contained in the training dataset,\n",
    "note this is a training dataset of *inputs*, not ground truth field\n",
    "solutions.\n",
    "\n",
    "In the following sections we cover two different applications of NFENs,\n",
    "where each application is a different form of input variability. The\n",
    "first section highlights our work in which covers variability in\n",
    "material diffusivity, where we show a heat or mass transfer problem\n",
    "through an inhomogenous media. The second section covers our work ,\n",
    "where we implement with NFEN framework with masks of complex geometries\n",
    "immersed in the domain. In each section we describe the loss function\n",
    "formulation, and present results in 2D and 3D for the given problem\n",
    "formulation.\n",
    "\n",
    "## Material Properties\n",
    "\n",
    "```{figure} Figures/anec-2d-single-query.png\n",
    "---\n",
    "name: fig-anec-2d-single-query\n",
    "---\n",
    "Left: contours of $ln(ν)$, the input diffusivity field; middle-left: NFEN prediction ($u_θ$); middle-right: reference numerical solution using FEM ($u^h$); right: contours of ($u_θ - u^h$).\n",
    "```\n",
    "\n",
    "\n",
    "For our first example problem we apply NFENs to the heat or mass\n",
    "transfer problem through an inhomogenous media. In this problem we\n",
    "created a dataset where each sample is a unique coefficient field\n",
    "defining the diffusivity. The NFEN learns a mapping between a\n",
    "*distribution* of diffusivity coefficient fields to the corresponding\n",
    "field solution of the Poisson equation. The dataset created\n",
    "contains $N$ different diffusivity fields. This dataset does not contain\n",
    "any ground truth field solutions for the corresponding diffusivity\n",
    "field. The ground truth field solutions are not required to train the\n",
    "NFEN since the residual is computed via FEM. The loss function for this\n",
    "NFEN formulation is:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\mathcal{L} = \\frac{1}{N} \\sum_{i = 1}^{N} \\int_{\\Omega} \\nu_i(\\mathbf{x})|\\mathbf{{\\nabla}}u_{\\theta}(\\mathbf{x}; q_i)|^2 d\\mathbf{x},\n",
    "\\end{aligned}$$\n",
    "\n",
    "where $q_i$ is our variable input, in this case the diffusivity\n",
    "coefficients, for NFEN, i.e., $\\nu_i$. In this problem both Dirichlet\n",
    "and Neumann boundary conditions are present. The Dirichlet conditions\n",
    "are applied exactly. The zero-Neumann condition is also applied exactly\n",
    "at the continuous level since the boundary integrals vanish at the\n",
    "continuous level.\n",
    "\n",
    "The parameters of NFEN are optimized via gradient descent to minimize\n",
    "this residual across the distribution of diffusivity coefficient fields\n",
    "contained in the training dataset. In our works we use the Adam\n",
    "optimizer, but any stochastic gradient descent method can be used with\n",
    "minor performance differences.\n",
    "\n",
    "Once the NFEN is trained it can approximate field solutions to unseen\n",
    "diffusivity fields, given they are drawn from the same distribution used\n",
    "to create the training dataset. This generalization ability from NFEN\n",
    "classifies it as a data-free **Neural Operator**, something in the\n",
    "current landscape that has not been achieved.\n",
    "\n",
    "In {numref}`fig-anec-2d-single-query` and {numref}`fig-anec-3d`, we present results for NFEN in two and three dimensional domains.\n",
    "\n",
    "```{figure} Figures/anec_3d.png\n",
    "---\n",
    "name: fig-anec-3d\n",
    "---\n",
    "Contours of $\\ln(\\nu(x,y,z))$ and the solution $u_{\\theta}(x,y,z)$ to the 3D Poisson's problem on a $ 64\\times 64\\times 64 $ mesh (for $ \\mathbf{a} = (-1,1.4,1.5,-1.3,-1.6,0.3) $).\n",
    "```\n",
    "\n",
    "\n",
    "## Immersed Object\n",
    "\n",
    "```{figure} Figures/2d_operator.png\n",
    "--- \n",
    "name: 2d_operator\n",
    "---\n",
    "Results for a *single* 2D NFEN which maps an unseen irregular geometry to the field solution of the Poisson equation. The first and fourth columns are the masks of the irregular geometry, the second and fifth columns are the predicted field solution, the third and sixth columns are the ground truth FEM field solution.\n",
    "```\n",
    "\n",
    "NFENs are very flexible and are even capable of learning field solutions\n",
    "of domains that contain irregular geometries such as {numref}`2d_operator`. For this problem NFEN\n",
    "learns a mapping between a mask of the irregular geometry in the domain\n",
    "and the field solution which satisfies the given PDE over the domain\n",
    "with the irregular geometry.\n",
    "\n",
    "Lets continue with the same Poisson equation example, but with the added\n",
    "boundary conditions for the irregular object. We now have,\n",
    "\n",
    "$$\\begin{align}\n",
    "    - \\mathbf{{\\nabla}}\\cdot [\\nu(\\mathbf{x}; q) \\mathbf{{\\nabla}}u_{\\theta}(\\mathbf{x}; q)] &= f(\\mathbf{x}) \\ \\ \\text{in} \\ \\ \\Omega, \\\\\n",
    "        u_{\\theta}(\\mathbf{x},q) &= 0, \\ \\text{on}\\ \\Gamma_B, \\\\\n",
    "    \\alpha u_{\\theta} + {\\beta} (\\nabla u_{\\theta}\\cdot \\hat{\\mathbf{x}{n}}) &= g(x) \\ \\ \\text{on}\\ \\ \\Gamma_o,\n",
    "    \\end{align}$$\n",
    "\n",
    "where, in this formulation, $q$ denotes the mask of the irregular\n",
    "geometry. We also have the added boundary condition which states the\n",
    "field solution is $0$ on the irregular geometry.\n",
    "\n",
    "When formulating the loss for this problem we need to pay special\n",
    "attention to how we compute the residual such that it respects the\n",
    "boundary conditions. In the Irregular Boundary Network work , we chose\n",
    "to strongly apply the Dirichlet boundary conditions over a discrete\n",
    "approximation of the irregular object. This discrete approximation of\n",
    "the irregular object is the binary mask of the irregular object itself,\n",
    "the input to the NFEN in this problem. Strongly applying the Dirichlet\n",
    "boundary conditions of the irregular object amounts to applying a\n",
    "threshold function over the predicted field solution by the Irregular\n",
    "Boundary Network. Once boundary conditions have been applied the field\n",
    "solution, with applied boundary conditions, is passed off to the\n",
    "FEM-based loss function to compute the residual as is done in the\n",
    "previous NFEN example.\n",
    "\n",
    "The training dataset for this problem is a distribution of irregular\n",
    "geometries, opposed to diffusivity fields in the previous problem. The\n",
    "distribution of these ’irregular geometries’ may vary wildly, as the\n",
    "binary images in {numref}`2d_operator` show. The results shown\n",
    "in {numref}`2d_operator` come from a similar\n",
    "distribution as the training dataset, but are all samples from the test\n",
    "dataset.\n",
    "\n",
    "The loss function for this problem is as follows,\n",
    "\n",
    "$$\\begin{aligned}\n",
    "    \\mathcal{L} = \\frac{1}{N} \\sum_{i = 1}^{N} \\int_{\\Omega} |\\mathbf{{\\nabla}}u_{\\theta}(\\mathbf{x}; q_i)|^2 d\\mathbf{x},\n",
    "\\end{aligned}$$\n",
    "\n",
    "where $N$ is a mini-batch of irregular geometries from the training\n",
    "dataset and $q_i$ is a single irregular geometry in the minibatch.\n",
    "\n",
    "As with the previous example problem the parameters of the NFEN are\n",
    "optimized with the Adam optimization algorithm and a standard UNet\n",
    "architecture. Once optimized the NFEN can reliably predict field\n",
    "solutions to irregular boundaries not contained in the training dataset.\n",
    "This second example supports the potential for neural networks to learn\n",
    "PDEs in a data-free regime without the need to be retrained for a new\n",
    "unseen input geometry.\n",
    "\n",
    "```{figure} Figures/engine_humvee.png\n",
    "---\n",
    "name: engine_humvee\n",
    "---\n",
    "Geometric model with the domain (left) and the field solution to Poisson's equation using the NFEN framework (right) for the Engine and the Humvee models.\n",
    "```\n",
    "```{figure} Figures/bunnies.png\n",
    "---\n",
    "name: bunnies\n",
    "---\n",
    "Left: the “Stanford bunny” placed within the background domain; Right: a single-instance NFEN for the Poisson equation is solved on the bunny using NFEN. The forcing $f = 500$, and the boundary condition is given by $u = 0$ on the surface of the bunny. This is an example where the solution is sought *inside* the object rather than outside.\n",
    "```\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "Overall Neural Finite Element Networks provide a clean and simple\n",
    "framework to learn Neural PDE Solvers and potentially Operators without\n",
    "the need for any expensive ground truth field solutions.\n",
    "\n",
    "-   Provides a flexible framework for any PDE.\n",
    "\n",
    "-   Approximates a discretized field solution.\n",
    "\n",
    "-   Is agnostic to the network input, e.g., diffusivity coefficient\n",
    "    fields or immersed irregular geometries.\n",
    "\n",
    "-   Can be used with any network architecture, Convolutional Neural\n",
    "    Networks, Vision Transformers, and even Graph Neural Networks.\n",
    "\n",
    "-   Builds off of decades of work dedicated to numerical methods.\n",
    "\n",
    "# Finite Element Methods\n",
    "\n",
    "Finite element methods (FEM) are a class of general numerical methods\n",
    "used to solve PDEs by discretizing the solution space into smaller\n",
    "components, called ’elements’. Each of these elements is representative\n",
    "of a smaller and much simpler equation than the PDE governing the given\n",
    "domain. One can solve this larger, more complex PDE by solving the\n",
    "system of smaller element-wise equations.\n",
    "\n",
    "```{figure} Figures/gauss_point.png\n",
    "---\n",
    "name: gauss_points\n",
    "---\n",
    "Left: A single 2D element in FEM, with black dots denoting “nodes\" and red dots denoting 2×2 Gauss quadrature points. Right: A finite element mesh, with 4×3 linear elements and 5×4 nodes. Each of these elements contains Gauss points for integration to be performed within that element. Within each element, the “first\" quadrature point (marked “1\" on left) is marked green, and others red.\n",
    "```\n",
    "\n",
    "```{figure} Figures/integrationFEM.png\n",
    "---\n",
    "name: int_gauss\n",
    "---\n",
    "Quadrature quantity evaluation in FEM context. $(U_θ^d)_M$ is the matrix view of the nodal values. $K_{GP1}$ is kernel containing the basis function values at “gauss point - 1\" (top left corner). This convolution results in the function values evaluated at the Gauss point “1\" of each element (marked green). $((U_θ^d)_{GP1})_M$ is the matrix of this result. Function values (or their derivatives) evaluated at Gauss points can then be used in any integral evaluation. For example, $\\int u^h dD = |J| \\sum_{I\\in M} \\left[\\sum_{i=1}^{4}(w_i (U^d_θ)_{GPi})_M\\right]$, where $|J|$ is the transformation Jacobian for integration and $w$ are the quadrature weights.\n",
    "```\n",
    "\n",
    "\n",
    "## Discretization: Elements and Basis Functions\n",
    "\n",
    "Most often the domain is defined by a mesh. For simplicity, we’ll assume\n",
    "our domain is a uniform grid in 2D, simply an image. The nodes defining\n",
    "our domain are the pixels in the image. The elements used in the FEM\n",
    "computations will be the area between neighborhoods of adjacent nodes.\n",
    "{numref}`gauss_points` provides a visual of\n",
    "constructing a single element. In this example an element can also be\n",
    "thought of as the resulting pixel from a 2D convolution operation with a\n",
    "kernel size of $(2,2)$ and a stride of $1$. The values of each element\n",
    "is defined by an interpolation operation between each node in the\n",
    "neighborhood. These interpolation functions, also known as basis\n",
    "functions, are non-parametric, and are defined *a priori*. These basis\n",
    "functions form the most critical part of the approximation of the\n",
    "solution function in the *spatial* domain. The choice of basis function\n",
    "is depenedent on the PDE being solved for. Linear bases are used most\n",
    "commonly because of their simpler implementation and interpretations,\n",
    "but higher-order bases are often used to obtain better accuracy.\n",
    "\n",
    "## Using FEM to Compute Spatial Derivatives of Field Solutions\n",
    "\n",
    "Going back to our example of the Poisson Equation, to solve for\n",
    "the field solution $u(x)$, where $u(x)$ is a uniform 2D grid, we need to\n",
    "compute the spatial derivatives since\n",
    "$\\nabla u(\\mathbf{x}) = u_{xx} + u_{yy}$. Computing the spatial\n",
    "derivatives of an image using FEM reduces to evaluating each $2\\times2$\n",
    "neighborhood of pixels with the set of basis functions at the desired\n",
    "derivative, i.e., to compute $u_{xx}$ we evaluate the field solution\n",
    "with the second derivative of the basis function for every element in\n",
    "the domain along the x-direction. One can also view this as a\n",
    "convolution operation with a $(2,2)$ kernel and stride $1$ where we\n",
    "define each element in the convolution kernel to be the second\n",
    "derivative of the basis function. The same operation is carried out\n",
    "again for the 2D case, but with the derivative in the y-direction. Now\n",
    "that we have the $u_{xx}$ and $y_{yy}$ terms all we need to do is\n",
    "evaluate the forcing function, $f(x)$, with our basis functions. Note,\n",
    "we evaluate the forcing function with the original basis functions, not\n",
    "the derivatives of the basis functions.\n",
    "\n",
    "## Summary\n",
    "\n",
    "FEM are fast approximations of the spatial derivatives in a domain\n",
    "defined by a mesh. If the mesh is posed as a uniform 2d grid, an image,\n",
    "then we can seamlessly integrate FEMs into the loss function of standard\n",
    "vision neural networks, such as CNNs and ViT. The ability to use such\n",
    "network archictectures alleviates the scaling bottleneck previously\n",
    "imposed on data-free Neural PDE Solvers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b56f29",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blogs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
